{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rubanenko_595_task6.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"kiJhA3CYih-W","colab_type":"text"},"cell_type":"markdown","source":["# Отчет по статье\n","\n","Разберем, что происходит в [данной статье](https://towardsdatascience.com/anime-recommendation-engine-from-matrix-factorization-to-learning-to-rank-845d4a9af335).\n","\n","## Данные\n","\n","В начале статьи рассказывается о данных. Они взяты с [соревнования на kaggle](https://www.kaggle.com/azathoth42/myanimelist). Авторы посмотрели, как вообще выглядят данные (первый параграф статьи, а также [папка на их github](https://github.com/Preetikasri/Anime-Recommendation-Engine/tree/master/dataset_explore)), но, какую-то полезную информацию для своего [итогового движка](https://github.com/Preetikasri/Anime-Recommendation-Engine/blob/master/SRC/rank_based_algo_code.py) брать не стали (итоговая версия работает только на рейтингах, без каких-либо дополнительных признаков).\n","\n","На [github](https://github.com/Preetikasri/Anime-Recommendation-Engine/tree/master/Notebook) есть пара ноутбуков с чисткой данных, но их результаты не используются в других ноутбуках -- авторы каждый раз по-своему выбирают данные, причем не всегда из одних и тех же файлов.\n","\n","## Алгоритмы\n","\n","В статье обсуждается 5 алгоритмов. Сначала идет три классических подхода к решению Collaborative Filtering. Затем идет два алгоритма Learn to Rank.\n","\n","### ALS\n","\n","ALS (Alternating Least Squares) -- итеративно ищет факторизованное представление матрицы рейтингов (R) в виде прозведения матриц U и P.\n","\n","Глобальная задача -- найти минимум $J = ||R - UP^{T}||_{2} + \\lambda(||U||_{2} + ||P||_{2})$. Она решается следующим итеративным алгоритмом:\n","1. Сначала фиксируется матрица P, и решается задача обычной линейной регрессии для U;\n","2. Затем фиксируется матрица U, и решается задача обычной линейной регрессии для P.\n","\n","$$\\forall{u_{i}}:\\ J(u_{i}) = ||R_{i} - u_{i}P^{T}||_{2} + \\lambda \\cdot ||u_{i}||_{2}$$\n","$$\\forall{p_{j}}:\\ J(p_{j}) = ||R_{j} - Up_{j}^{T}||_{2} + \\lambda \\cdot ||p_{j}||_{2}$$\n","\n","Решение:\n","\n","$$u_{i} = (P^{T}P + \\lambda I)^{-1}P^{T}R_{i}$$\n","$$p_{j} = (U^{T}U + \\lambda I)^{-1}U^{T}R_{j}$$\n","\n","### SVD\n","\n","Решает глобальную задачу с помощью SVD разложения.\n","\n","### NN\n","\n","Архитектура сети:  \n","![](https://cdn-images-1.medium.com/max/1600/1*aLJrZkD0tF-TlHAfyCcBRA.png)\n","\n","### Промежуточные результаты\n","\n","Каждый из алгоритмов давал хорошие результаты, но еще большего успеха получилось добиться после ансамблирования всех трех алгоритмов.\n","\n","![](https://cdn-images-1.medium.com/max/1600/1*xf7xhhAONUsCFjSDAZmbWg.png)\n","\n","### Eigen Rank\n","\n","Pipeline алгоритма Eigen Rank (на примере рекомендаций аниме):\n","* Для каждого пользователя сделать следующее\n","    * Используя корелляционный коэффициент Кендала Тау найти ближайших соседей ($N_{u}$);\n","    * Посчитать функцию предпочтения для каждой пары объектов.\n","* С помощью жадного алгоритма провести определение рангов объектов.\n","\n","Функция предпочтения:  \n","![](https://cdn-images-1.medium.com/max/1600/1*cJJwvB814KjOJGuI2f3k3w.png)\n","\n","### LambdaMART\n","\n","LambdaMART является комбинацией LambdaRank и MART. LambdaRank предлагает новую функцию потерь, по которой будет производится оптимизация RankNet (стремится минимизировать количество инверсий в ранжировании; используется SGD), а MART -- использует градиентный бустинг над деревьями для решения задач предсказания. В [оригинальной статье](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf) утверждается, что каждый подход улучшает результат предыдущего (RankNet < LambdaRank < LambdaMART).\n","\n","### Финальные результаты\n","\n","Последние два алгоритма обучались на меньшей выборке, поэтому результаты не такие хорошие, как раньше.\n","\n","|            | NDCG | MAP  |\n","|------------|------|------|\n","| Eigen Rank | 0.72 | 0.63 |\n","| LambdaMART | 0.60 | 0.56 |\n","\n","## Метрики\n","\n","Авторы сначала использовали неподходящую метрику (RMSE), поэтому в конце статьи приведен обзор популярных метрик для задач рекомендации и ранжирования.\n","\n","### NDCG\n","\n","NDCG (Normalized Discounted Cumulative Gain) -- показывает, как сильно текущий рейтинг отличается от идеального (т.е. правильно отсортированных данных). NDCG оприается на два предположения:\n","1. Высоко-релевантные документы полезнее, если появляются раньше в выдаче;\n","2. Высоко-релевантные документы важнее просто релевантных документов, которые в свою очередь важнее нерелевантных документов.\n","\n","NDCG@K -- вычисления проводятся для первых K рекомендаций.\n","\n","Формулы, по которым рассчитывается NDCG:\n","$$NDCG_{p} = \\cfrac{DCG_{p}}{IDCG_{p}}$$\n","$$DCG_{p} = \\sum_{i=1}^{p}\\cfrac{2^{rel_{i}} - 1}{log_{2}(i + 1)}$$\n","$$IDCG_{p} = \\sum_{i=1}^{|REL|}\\cfrac{2^{rel_{i}} - 1}{log_{2}(i + 1)}$$\n","\n","Можно считать DCG (и, соответственно, NDCG) по-другим формулам, но приведенные выше сильнее зависят от релевантности документов.\n","\n","### MAP\n","\n","MAP (Mean Average Precision) -- показывает среднюю точность ранжирования.\n","\n","$$MAP = \\cfrac{\\sum_{q=1}^{Q}AP(q)}{Q}$$\n","$$AP = \\cfrac{\\sum_{k=1}^{n}P(k) \\cdot rel(k)}{\\text{number of relevant documents}}$$\n","\n","Q -- число запросов; P(k) -- precision первых k документов, rel(k) -- индикатор того, релевантен ли документ с рангом k.\n","\n","MAP@K -- вычисления проводятся для первых K рекомендаций.\n","\n","## Заключение\n","\n","Статья описывает, как и что студенты делали в качестве проекта по курсу -- поэтому в ней, как мне кажется, не хватает формальных объяснений. В целом описано много методов, о которых можно дальше искать информацию.\n","\n","Репозиторий плохо организован -- разделение по папкам не помогает разбираться в коде, отсутствует README, много каких-то незапущенных ячеек, комментариев."]},{"metadata":{"id":"hfNsODopipyw","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}