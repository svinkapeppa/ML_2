{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Теоретическая часть</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Контрольные вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Что является объектом в задаче обучения ранжированию? Какой смысл имеют целевые метки? Какие объекты сравнимы между собой?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Объектами выступают пары (Запрос, Документ)*\n",
    "* *Целевая метка отвечает за релевантность документа для данного запроса (то есть говорит, насколько хорошо данный текст подходит к полученному запросу)*\n",
    "* *Сравнимыми между собой являются только те пары, которые отвечают одному и тому же запросу*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** В чём преимущество метрики NDCG перед метрикой MAP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MAP работает с бинарной релевантностью: релевантен или не релевантен данный объект, в то время как NDCG позволяет релевантности быть некоторым числом, показывающим степень этой релевантности (аналогия к классификацией и регрессией). Преимущество - NDCG можно использовать вместо MAP (выберем порог), а наоборот уже не получится.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Опишите причину неустойчивости PLSA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*В PLSA число параметров линейно зависит от размера корпуса. То есть после обучения у нас будут много параметров, которые не определяют какой-то важный признак, а просто являются проверкой для текстов из корпуса для обучения.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** На каких выборках наиболее заметна разница в работе PLSA и LDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LDA обычно работает лучше чем PLSA, потому что легко обобщается на новые тексты. В PLSA вероятность документа - какое-то фиксированное число, полученное из датасета. Если такого документа не было, то и его вероятность неизвестна. В LDA же благодаря распределению Дирихле для неизвестных документов можно получить вероятность: взять ее из распределения и затем как-то уточнять его.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** По каким причинам в ЕМ-алгоритме для тематического моделирования E-шаг встраивается внутрь М-шага?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*В straightforward подходе приходится хранить трехмерную матрицу c $n_{dwt}$, и использовать ее для подсчета $n_{wt}, n_{td}, \\ldots$. Если встроить E-шаг в M-шаг, то ее хранить уже не нужно (вычисление $n_{wt}, n_{td}, \\ldots$ происходит сразу) -> ускоряемся.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.**  Опишите применение тематического моделирования в задаче информационного поиска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Тематическое моделирование может помочь в задачах:*\n",
    "* *Определение темы текста*\n",
    "* *Классификация корпуса текстов*\n",
    "* *Кластеризация текстов*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** В чем основная причина сложности обработки русского языка по сравнению с английским?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Во-первых, в английском языке более четкая структура предложений. Во-вторых, там нет падежей. Да и вообще, словоформ меньше. Также в русском есть слова, которые могут быть разными частями речи, а писаться по разному - омонимия (это более общее понятие, которое так же сильно мешает обрабатывать тексты).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.**  Каким образом парсинг зависимостей между словами помогает в решении задач обработки естественного языка?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Можно создать более адекватные модели. Например, расммотрим задачу машинного перевода. Пусть модель читает слово и предсказывает следующее. Если известны зависимости между словами, то модель будет понимать, что если сейчас рассматривается предлог, то после него вероятнее всего будет существительное, а не глагол -> меньше шансов ошибиться (получится хорошая модель).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.**  Что такое кореференции?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Кореференция - отсылка к объекту при помощи специальных указателей. Это могут быть местоимения, аббревиатуры, словообразования. Они могут привнести новые признаки - поэтому кореференции надо уметь разрешать. Тут может помочь лемматизация, стэмминг, удаление стоп-слов, удаление слишком коротких слов.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.**  В чем отличие между CBOW и Skip-gram?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*В CBOW мы по сумме контекстных векторов предсказывается вектор центрального слова, а в Skip-gram - наоборот, контекст по центральному слову.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 1**\n",
    "\n",
    "Посчитайте PageRank для заданного графа вручную и при помощи алгоритма, описанного в семинаре. Результаты сравните.\n",
    "\n",
    "<img width=300 src=\"./gr1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Решение**\n",
    "\n",
    "Всего на графе 9 вершин. Занумеруем их следующим образом:\n",
    "* 0 - центральная\n",
    "* номера с 1 по 8 присвоим вершинам по часовой стрелке, начиная с самой верхней\n",
    "\n",
    "Отметим, что в силу симметрии, здесь будет только два разных значения $PR$ - для центральной вершины, и для всех остальных. Для удобства обозначим их за $y$ и $x$.\n",
    "\n",
    "Будем считать, что $\\delta = 0.85.$\n",
    "\n",
    "$$PR(0) = \\cfrac{1 - 0.85}{9} + 0.85 \\cdot \\sum_{i \\in \\{1, \\ldots, 8\\}} \\cfrac{PR(i)}{3}$$\n",
    "$$PR(i) = \\cfrac{1 - 0.85}{9} + 0.85 \\cdot \\left[\\cfrac{PR(0)}{9} + \\sum_{j \\in \\{j-1, j+1\\}} \\cfrac{PR(j)}{3}\\right]$$\n",
    "\n",
    "Эту систему можно переписать в следующем виде:\n",
    "\n",
    "$$y = \\cfrac{1}{60} + 0.85 \\cdot \\cfrac{8x}{3}$$\n",
    "$$x = \\cfrac{1}{60} + 0.85 \\cdot \\left[\\cfrac{y}{9} + \\cfrac{2x}{3}\\right]$$\n",
    "\n",
    "Решая ее, получим следующее\n",
    "\n",
    "$$PR(0) = y = \\cfrac{729}{3552} \\approx 0.205$$\n",
    "$$PR(i) = x = \\cfrac{197}{2368} \\approx 0.083$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pages = 9\n",
    "M_counts = np.zeros((n_pages, n_pages))\n",
    "\n",
    "M_counts[:,0] = 1\n",
    "M_counts[0,1] = 1\n",
    "M_counts[2,1] = 1\n",
    "M_counts[8,1] = 1\n",
    "M_counts[0,2] = 1\n",
    "M_counts[1,2] = 1\n",
    "M_counts[3,2] = 1\n",
    "M_counts[0,3] = 1\n",
    "M_counts[2,3] = 1\n",
    "M_counts[4,3] = 1\n",
    "M_counts[0,4] = 1\n",
    "M_counts[3,4] = 1\n",
    "M_counts[5,4] = 1\n",
    "M_counts[0,5] = 1\n",
    "M_counts[4,5] = 1\n",
    "M_counts[6,5] = 1\n",
    "M_counts[0,6] = 1\n",
    "M_counts[5,6] = 1\n",
    "M_counts[7,6] = 1\n",
    "M_counts[0,7] = 1\n",
    "M_counts[6,7] = 1\n",
    "M_counts[8,7] = 1\n",
    "M_counts[0,8] = 1\n",
    "M_counts[7,8] = 1\n",
    "M_counts[1,8] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.empty((n_pages, n_pages))\n",
    "for j in range(n_pages):\n",
    "    M[:,j] = M_counts[:,j] / M_counts[:,j].sum()\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_M(M):\n",
    "    n_pages = M.shape[0]\n",
    "    np.testing.assert_equal(M.shape[0], M.shape[1], err_msg = 'M should be square')\n",
    "    np.testing.assert_array_almost_equal(M.sum(axis=0), np.ones((n_pages)), \n",
    "                                         err_msg = 'assert each column sums to one (M is assumed column-stochastic)')\n",
    "    for j in range(n_pages):\n",
    "        M_column = M[:,j]\n",
    "        n_nonzero = np.count_nonzero(M[:,j])\n",
    "        np.testing.assert_array_almost_equal(M_column[M_column.nonzero()], np.ones((n_nonzero)) / n_nonzero,\n",
    "                                             err_msg = 'in column %g, all non-zero entries should be equal (and equal to 1 divided by their number)' % j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_M(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(M, d=0.85, square_error=1e-6):\n",
    "    n_pages = M.shape[0]\n",
    "    v = np.random.rand(n_pages)\n",
    "    v = v / v.sum()\n",
    "    last_v = np.ones((n_pages))\n",
    "    M_hat = d * M + (1-d)/n_pages * np.ones((n_pages, n_pages))\n",
    "    while np.square(v - last_v).sum() > square_error:\n",
    "        last_v = v\n",
    "        v = M_hat.dot(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.252, 0.094, 0.093, 0.094, 0.093, 0.094, 0.093, 0.094, 0.093])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagerank(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ответы разные, потому что алгоритм с семинара не учитывает телепортацию.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 2**\n",
    "\n",
    "Пользователь браузера в дополнение к кликам по ссылкам один раз может перейти по кнопке *Назад* и вернуться на предыдущую страницу. Можно ли такую модель описать с помощью однородной марковской цепи? Если да, опишите, если нет, докажите."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Решение**\n",
    "\n",
    "Введем дополнительный символ - $\\$$, который будет показывать, что страницы *Назад* не существует. Будем работать со множеством состояний $\\mathbf{X} = \\{(u, v)\\ \\|\\ u \\in V,\\ v \\in V \\cup \\{\\$\\}\\}$. Пусть $p$ - вероятность телепоратции, $q$ - вероятность *Назад*. Тогда для переходных вероятностей можем записать следующее\n",
    "\n",
    "$$p_{ij} = \\cfrac{p}{|V|} + \\cfrac{1 - p - q}{N_{i}} \\cdot I\\{(u_{i}, u_{j}) \\in E\\} + q \\cdot I\\{\\xi_{0} = (i, k),\\ k \\ne \\$\\},\\ N_{i} > 0$$\n",
    "$$p_{ij} = \\cfrac{1 - q}{|V|} + q \\cdot I\\{\\xi_{0} = (i, k),\\ k \\ne \\$\\},\\ N_{i} = 0$$\n",
    "\n",
    "где $N_{i} = \\#\\{\\ j\\ \\|\\ (u_{i}, u_{j}) \\in E\\}$.\n",
    "\n",
    "Матрица переходных вероятностей задает марковскую цепь.\n",
    "\n",
    "Так как $p_{ij}$ не зависит от $n$, то марковская цепь является однородной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3** (3%)\n",
    "\n",
    "Опишите вероятностные предположения, на которые опирается  TF-IDF при подсчете вероятностей.\n",
    "\n",
    "Пусть задана колекция текстовых документов $d_1, d_2,\\ldots, d_n$, состоящая из двух видов слов: $w_1$ и $w_2$. В документе $d_i$ ровно $k_{i1}$ слов $w_1$ и $k_{i2}$ слов $w_2$.\n",
    "\n",
    "Оцените вероятность втретить $k$ раз слово $w_1$. Сравните с оценкой вероятности, используемой в TF-IDF. \n",
    "\n",
    "Совпадают ли эти значения? Если нет, проведите анализ \"источника\" различий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Решение**\n",
    "\n",
    "* Предположения\n",
    "\n",
    "Предполагается, что появление слов в документе не зависит от документа.\n",
    "\n",
    "* tf-idf\n",
    "\n",
    "$$P = \\left(\\cfrac{\\sum_{i=1}^{n}I\\{k_{i1} > 0\\}}{n}\\right)^{k}$$\n",
    "\n",
    "* Честный подход\n",
    "\n",
    "$$P = \\sum_{S} \\prod_{i=1}^{n} P(i, s_{ji})$$\n",
    "$$P(i, s_{ji}) = \\cfrac{k_{i1}}{k_{i1} + k_{i2}} \\cdot \\cfrac{k_{i1} - 1}{k_{i1} + k_{i2} - 1} \\cdot \\ldots \\cdot \\cfrac{k_{i1} - s_{ji} + 1}{k_{i1} + k_{i2} - s_{ji} + 1}$$\n",
    "$$S = \\{S_{j}: \\sum_{i=1}^{n}s_{ji} = k,\\ s_{ji} < k_{i1}\\}$$\n",
    "\n",
    "Различие заключается в том, что tf-idf подходит смотрит лишь на то, есть ли слово в документе, или нет, в то время как честный подход еще и учитывает, сколько этих слов было в документе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 4**\n",
    "\n",
    "Задано 10 документов. Их отранжировали идеально, а затем 4 и 6 документы поменяли местами. \n",
    "Подсчитайте коэффициент ранговой корреляции ($\\tau$ Кенделла).\n",
    "\n",
    "**Решение**\n",
    "\n",
    "После того, как местами поменяли 4 и 6 документы, появилось 3 инверсии порядка. Тогда \n",
    "\n",
    "$$\\tau = 1 - 2 \\cdot \\cfrac{2}{9 \\cdot 10} \\cdot 3 = \\cfrac{13}{15}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 5**\n",
    "\n",
    "С какой целью общеупотребительные слова исключают из рассмотрения при построении тематической модели? Если их не исключать, как это отразится на матрицах $\\Phi$ и $\\Theta$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Решение**\n",
    "\n",
    "Если оставить общеупотребительные слова, то при вычислении элементов матрицы $\\Phi_{0}$ произойдет следующее: для общеупотребительных слов $\\phi_{wt}$ станет очень большим числом (так как $n_{wt}$ будет большим, а $n_{t}$ не изменится). Аналогично будут увеличиваться $\\theta_{td}$ (так как в теме $t$ теперь могут найтись общеупотребительные слова). Тогда матрицы $\\Phi_{0}$ и $\\Theta_{0}$ не будут разреженными - не будут устойчиво восстанавливаться матрицы $\\Phi$ и $\\Theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 6**\n",
    "\n",
    "Задано значение $KL(P∥Q)$. Можно ли оценить значение $KL(Q∥P)$? Если да, то оцените; если нет, то обоснуйте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Решение**\n",
    "\n",
    "* Если KL = 0, то RKL = 0\n",
    "* Если KL > 0, то RKL может относиться к KL как угодно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL: 0.0964\tRKL: 0.0863\n"
     ]
    }
   ],
   "source": [
    "P = [0.36, 0.48, 0.16] # Binomial distribution with N = 2, p = 0.4\n",
    "Q = [0.333, 0.333, 0.333] # Uniform distribution with N = 2\n",
    "\n",
    "kl = 0\n",
    "for i in range(len(P)):\n",
    "    kl += Q[i] * np.log(Q[i] / P[i])\n",
    "\n",
    "reverse_kl = 0\n",
    "for i in range(len(P)):\n",
    "    reverse_kl += P[i] * np.log(P[i] / Q[i])\n",
    "\n",
    "print('KL: {:.4f}\\tRKL: {:.4f}'.format(kl, reverse_kl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL: 0.1583\tRKL: 0.2051\n"
     ]
    }
   ],
   "source": [
    "P = [0.25, 0.25, 0.25, 0.25] # Uniform distribution with N = 3\n",
    "Q = [0.216, 0.432, 0.288, 0.064] # Binomial distribution with N = 3, p = 0.4\n",
    "\n",
    "kl = 0\n",
    "for i in range(len(P)):\n",
    "    kl += Q[i] * np.log(Q[i] / P[i])\n",
    "\n",
    "reverse_kl = 0\n",
    "for i in range(len(P)):\n",
    "    reverse_kl += P[i] * np.log(P[i] / Q[i])\n",
    "\n",
    "print('KL: {:.4f}\\tRKL: {:.4f}'.format(kl, reverse_kl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL: 0.1622\tRKL: 0.1622\n"
     ]
    }
   ],
   "source": [
    "P = [0.36, 0.48, 0.16] # Binomial distribution with N = 2, p = 0.4\n",
    "Q = [0.16, 0.48, 0.36] # Binomial distribution with N = 2, p = 0.6\n",
    "\n",
    "kl = 0\n",
    "for i in range(len(P)):\n",
    "    kl += Q[i] * np.log(Q[i] / P[i])\n",
    "\n",
    "reverse_kl = 0\n",
    "for i in range(len(P)):\n",
    "    reverse_kl += P[i] * np.log(P[i] / Q[i])\n",
    "\n",
    "print('KL: {:.4f}\\tRKL: {:.4f}'.format(kl, reverse_kl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 7**\n",
    "\n",
    "Рассмотрим пример из семинара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">But \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is starting from behind. The company made a late push\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "into hardware, and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s Siri, available on \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    iPhones\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Alexa\n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "software, which runs on its \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Echo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Dot\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " devices, have clear leads in\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "consumer adoption.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "text = \"\"\"But Google is starting from behind. The company made a late push\n",
    "into hardware, and Apple’s Siri, available on iPhones, and Amazon’s Alexa\n",
    "software, which runs on its Echo and Dot devices, have clear leads in\n",
    "consumer adoption.\"\"\"\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите способ устранить хотябы часть некорректных меток географических объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">But \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is starting from behind. The company made a late push into hardware, and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s Siri, available on \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    iPhones\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Alexa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " software, which runs on its \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Echo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Dot\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " devices, have clear leads in consumer adoption.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Idea: seems that for spacy \\n plays big role for NER\n",
    "# Solution: let's flatten the text\n",
    "# As we can see, there is no strange (blank) `GPE` labels\n",
    "text = 'But Google is starting from behind. The company made a late push into hardware, ' + \\\n",
    "    'and Apple’s Siri, available on iPhones, and Amazon’s Alexa software, ' + \\\n",
    "    'which runs on its Echo and Dot devices, have clear leads in consumer adoption.'\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">But \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is starting from behind. The company made a late push into hardware, and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s Siri, available on \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    iPhones\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Alexa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " software, which runs on its \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "     Echo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Dot\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " devices, have clear leads in consumer adoption.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Idea: let's play around `Echo` word\n",
    "# Solution: add 1 additional whitespace before `Echo` word\n",
    "# As we can see, `Echo` gets correct (I assume so) label\n",
    "text = 'But Google is starting from behind. The company made a late push into hardware, ' + \\\n",
    "    'and Apple’s Siri, available on iPhones, and Amazon’s Alexa software, ' + \\\n",
    "    'which runs on its  Echo and Dot devices, have clear leads in consumer adoption.'\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Практическая часть</h1>\n",
    "\n",
    "* Ссылка на контест: http://www.kaggle.com/c/mipt-ml-fall2018-hw3\n",
    "\n",
    "# Описание форматов\n",
    "\n",
    "Вам выдается 4 файла:\n",
    "\n",
    "* `relevance_train.csv` --- обучающая выборка пар запрос-документ и асессорские метки релевантности (все документы имеют одинаковую релевантность, т.е. можно считать, что выданы просто релевантные документы).\n",
    "* `relevance_test.csv` --- тестовая выборка пар запрос-документ\n",
    "* `queries.csv` --- запросы из `relevance_test.csv` и `relevance_train.csv` (в формате id запроса, текст запроса)\n",
    "* `documents.csv` --- документы из `relevance_test.csv` и `relevance_train.csv`\n",
    "\n",
    "Колонки в первых трёх файлах могут быть следующего типа:\n",
    "\n",
    "* `QueryId` --- уникальный номер запроса\n",
    "* `DocumentId` --- номер документа, не повторяется для одного запроса\n",
    "* `Relevance` --- асессорская метка релевантности\n",
    "\n",
    "Формат файла ответов приведен ниже. Пары запрос-документ должны соответсвовать файлу `relevance_test.csv` и должны быть упорядочены по убыванию построенной функции релевантности.\n",
    "\n",
    "Файл `stopwords.csv` содержит стоп-слова, а `sample_submission.csv` - это пример сабмита, который нужно отправлять в качестве ответа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/king/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from string import punctuation\n",
    "from nltk import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to create corpus\n",
    "def read_texts(filepath='data/documents.csv'):\n",
    "    # Placeholders\n",
    "    texts = []\n",
    "    text = []\n",
    "\n",
    "    # Split large file into lines\n",
    "    with open(filepath) as fd:\n",
    "        # Don't forget to lower each line\n",
    "        lines = [line.lower().strip() for line in fd]\n",
    "\n",
    "    # New text starts with a special line -> use it to divide texts\n",
    "    for line in lines:\n",
    "        if re.match('\\*text \\d+', line):\n",
    "            text = ' '.join(text)\n",
    "            if len(text) > 0:\n",
    "                texts.append(text)\n",
    "            text = []\n",
    "        else:\n",
    "            text.append(line)\n",
    "\n",
    "    # Don't forget about last text\n",
    "    text = ' '.join(text)\n",
    "    if len(text) > 0:\n",
    "        texts.append(text)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we do the same stuff with queries\n",
    "def read_queries(filepath='data/queries.csv'):\n",
    "    # Placeholder\n",
    "    queries = []\n",
    "\n",
    "    # Split large file into lines\n",
    "    with open(filepath) as fd:\n",
    "        # Don't forget to lower each line\n",
    "        lines = [line.lower().strip() for line in fd]\n",
    "\n",
    "    # Remove numbers from the start of the each line\n",
    "    for line in lines:\n",
    "        line = re.sub('^\\d+,', '', line)\n",
    "        queries.append(line)\n",
    "\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap stopwords retrival into nice function\n",
    "def read_stopwords(filepath='data/stopwords.csv'):   \n",
    "    with open(filepath) as fd:\n",
    "        # Don't forget to lower each word\n",
    "        stopwords = [line.lower().strip() for line in fd]\n",
    "    \n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: if word lies in stopwords, than we skip it\n",
    "def remove_stopwords(texts, stopwords):\n",
    "    clear_texts = []\n",
    "    \n",
    "    for text in texts:\n",
    "        clear_text = []\n",
    "        for word in text.split():\n",
    "            if not (word in stopwords):\n",
    "                clear_text.append(word)\n",
    "        clear_text = ' '.join(clear_text)\n",
    "        clear_texts.append(clear_text)\n",
    "    \n",
    "    return clear_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: if character is a punctuation symbol, than we skip it\n",
    "def remove_punctuation(texts):\n",
    "    clear_texts = []\n",
    "    \n",
    "    for text in texts:\n",
    "        clear_text = []\n",
    "        for word in text:\n",
    "            if not (word in punctuation):\n",
    "                clear_text.append(word)\n",
    "        clear_text = ''.join(clear_text)\n",
    "        # Strip and sub, because we don't need extra whitespaces\n",
    "        clear_texts.append(re.sub('\\s+', ' ', clear_text).strip())\n",
    "    \n",
    "    return clear_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: let's just stem, because it's a well-known practice\n",
    "def stem(texts):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(word) for word in word_tokenize(sentence)]) for sentence in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice wrapper\n",
    "def process_texts(texts, stopwords):\n",
    "    texts = remove_stopwords(texts, stopwords)\n",
    "    texts = remove_punctuation(texts)\n",
    "    texts = stem(texts)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основная идея:** давайте просто переведем все в вектора (то есть заэмбедим все), а затем для векторов запросов найдем ближайшие k векторов текстов. Я что-то похожее делал в домашке по нлп на кафедре, поэтому решил и здесь попробовать.\n",
    "\n",
    "В итоге я попробовал разные вариации параметров, но подход не менялся."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = read_texts()\n",
    "queries = read_queries()\n",
    "stopwords= read_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = process_texts(texts, stopwords)\n",
    "queries = process_texts(queries, stopwords)\n",
    "corpus = texts + queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = []\n",
    "for query in queries:\n",
    "    row = []\n",
    "    for text in texts:\n",
    "        q_emb = vectorizer.transform([query])\n",
    "        t_emb = vectorizer.transform([text])\n",
    "        row.append(cosine_similarity(q_emb, t_emb)[0][0])\n",
    "    matrix.append(row)\n",
    "matrix = np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = [row.argsort()[-10:][::-1] for row in matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/relevance_test.csv') as fd:\n",
    "    lines = [line.lower().strip() for line in fd]\n",
    "\n",
    "text_idxs = []\n",
    "query_idxs = []\n",
    "    \n",
    "for line in lines[1:]:\n",
    "    query_idxs.append(int(line))\n",
    "    text_idxs.append(places[int(line) - 1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/submission_30_10_2018_23_10.csv', 'w') as fd:\n",
    "    fd.write('QueryId,DocumentId')\n",
    "    for idx in range(len(text_idxs)):\n",
    "        for i in range(len(text_idxs[idx])):\n",
    "            fd.write('\\n{},{}'.format(query_idxs[idx], text_idxs[idx][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = [row.argsort()[-20:][::-1] for row in matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/relevance_test.csv') as fd:\n",
    "    lines = [line.lower().strip() for line in fd]\n",
    "\n",
    "text_idxs = []\n",
    "query_idxs = []\n",
    "    \n",
    "for line in lines[1:]:\n",
    "    query_idxs.append(int(line))\n",
    "    text_idxs.append(places[int(line) - 1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/submission_30_10_2018_23_20.csv', 'w') as fd:\n",
    "    fd.write('QueryId,DocumentId')\n",
    "    for idx in range(len(text_idxs)):\n",
    "        for i in range(len(text_idxs[idx])):\n",
    "            fd.write('\\n{},{}'.format(query_idxs[idx], text_idxs[idx][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = read_texts()\n",
    "queries = read_queries()\n",
    "stopwords= read_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = process_texts(texts, stopwords)\n",
    "queries = process_texts(queries, stopwords)\n",
    "corpus = texts + queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = []\n",
    "for query in queries:\n",
    "    row = []\n",
    "    for text in texts:\n",
    "        q_emb = vectorizer.transform([query])\n",
    "        t_emb = vectorizer.transform([text])\n",
    "        row.append(cosine_similarity(q_emb, t_emb)[0][0])\n",
    "    matrix.append(row)\n",
    "matrix = np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = [row.argsort()[-10:][::-1] for row in matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/relevance_test.csv') as fd:\n",
    "    lines = [line.lower().strip() for line in fd]\n",
    "\n",
    "text_idxs = []\n",
    "query_idxs = []\n",
    "    \n",
    "for line in lines[1:]:\n",
    "    query_idxs.append(int(line))\n",
    "    text_idxs.append(places[int(line) - 1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/submission_31_10_2018_17_30.csv', 'w') as fd:\n",
    "    fd.write('QueryId,DocumentId')\n",
    "    for idx in range(len(text_idxs)):\n",
    "        for i in range(len(text_idxs[idx])):\n",
    "            fd.write('\\n{},{}'.format(query_idxs[idx], text_idxs[idx][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = read_texts()\n",
    "queries = read_queries()\n",
    "stopwords= read_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_texts(texts, stopwords):\n",
    "    texts = remove_stopwords(texts, stopwords)\n",
    "    texts = remove_punctuation(texts)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = _process_texts(texts, stopwords)\n",
    "queries = _process_texts(queries, stopwords)\n",
    "corpus = texts + queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = []\n",
    "for query in queries:\n",
    "    row = []\n",
    "    for text in texts:\n",
    "        q_emb = vectorizer.transform([query])\n",
    "        t_emb = vectorizer.transform([text])\n",
    "        row.append(cosine_similarity(q_emb, t_emb)[0][0])\n",
    "    matrix.append(row)\n",
    "matrix = np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = [row.argsort()[-10:][::-1] for row in matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/relevance_test.csv') as fd:\n",
    "    lines = [line.lower().strip() for line in fd]\n",
    "\n",
    "text_idxs = []\n",
    "query_idxs = []\n",
    "    \n",
    "for line in lines[1:]:\n",
    "    query_idxs.append(int(line))\n",
    "    text_idxs.append(places[int(line) - 1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/submission_31_10_2018_18_40.csv', 'w') as fd:\n",
    "    fd.write('QueryId,DocumentId')\n",
    "    for idx in range(len(text_idxs)):\n",
    "        for i in range(len(text_idxs[idx])):\n",
    "            fd.write('\\n{},{}'.format(query_idxs[idx], text_idxs[idx][i]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
